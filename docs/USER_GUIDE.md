# Logstash Parser ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [åŸºæœ¬ç”¨æ³•](#åŸºæœ¬ç”¨æ³•)
- [é«˜çº§ç‰¹æ€§](#é«˜çº§ç‰¹æ€§)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
uv add logstash-parser
```

### ç¬¬ä¸€ä¸ªç¤ºä¾‹

```python
from logstash_parser import parse_logstash_config

# è§£æ Logstash é…ç½®
config_text = """
filter {
    grok {
        match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
}
"""

ast = parse_logstash_config(config_text)
print(ast.to_logstash())
```

---

## åŸºæœ¬ç”¨æ³•

### 1. è§£æé…ç½®

```python
from logstash_parser import parse_logstash_config

config_text = """
input {
    beats {
        port => 5044
        host => "0.0.0.0"
    }
}

filter {
    if [type] == "nginx" {
        grok {
            match => { "message" => "%{COMBINEDAPACHELOG}" }
        }
    }
}

output {
    elasticsearch {
        hosts => ["localhost:9200"]
        index => "logs-%{+YYYY.MM.dd}"
    }
}
"""

# è§£æä¸º AST
ast = parse_logstash_config(config_text)
```

### 2. è½¬æ¢ä¸º Python å­—å…¸

```python
# è½¬æ¢ä¸º dictï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
python_dict = ast.to_python()

print(python_dict)
# {
#     "input": [...],
#     "filter": [...],
#     "output": [...]
# }
```

### 3. è½¬æ¢ä¸º Pydantic Schema

```python
# è½¬æ¢ä¸º Pydantic Schema
schema = ast.to_python(as_pydantic=True)

print(type(schema))  # <class 'ConfigSchema'>
```

### 4. åºåˆ—åŒ–ä¸º JSON

```python
# åºåˆ—åŒ–ä¸º JSON
json_str = schema.model_dump_json(indent=2)

print(json_str)
# {
#   "config": [
#     {
#       "plugin_section": {
#         "filter": [...]
#       }
#     }
#   ]
# }
```

**æ³¨æ„**: JSON ä½¿ç”¨ snake_case å­—æ®µå,ç»“æ„æ›´ç®€æ´ã€‚

### 5. ä» JSON ååºåˆ—åŒ–

```python
from logstash_parser.schemas import ConfigSchema

# ä» JSON ååºåˆ—åŒ–
loaded_schema = ConfigSchema.model_validate_json(json_str)
```

### 6. è½¬æ¢å› AST

```python
from logstash_parser.ast_nodes import Config

# ä» Schema è½¬æ¢å› AST
reconstructed_ast = Config.from_python(loaded_schema)
```

### 7. ç”Ÿæˆ Logstash é…ç½®

```python
# ç”Ÿæˆ Logstash é…ç½®æ–‡æœ¬
output_text = reconstructed_ast.to_logstash()

print(output_text)
```

---

## é«˜çº§ç‰¹æ€§

### 1. éå† AST

```python
def traverse_ast(node, depth=0):
    """é€’å½’éå† AST"""
    indent = "  " * depth
    print(f"{indent}{type(node).__name__}")

    if hasattr(node, 'children'):
        for child in node.children:
            traverse_ast(child, depth + 1)

traverse_ast(ast)
```

### 2. æŸ¥æ‰¾ç‰¹å®šèŠ‚ç‚¹

```python
def find_plugins(node, plugin_name):
    """æŸ¥æ‰¾ç‰¹å®šåç§°çš„æ’ä»¶"""
    from logstash_parser.ast_nodes import Plugin

    plugins = []

    if isinstance(node, Plugin) and node.plugin_name == plugin_name:
        plugins.append(node)

    if hasattr(node, 'children'):
        for child in node.children:
            plugins.extend(find_plugins(child, plugin_name))

    return plugins

# æŸ¥æ‰¾æ‰€æœ‰ grok æ’ä»¶
grok_plugins = find_plugins(ast, "grok")
```

### 3. ä¿®æ”¹ AST

```python
from logstash_parser.ast_nodes import (
    Plugin, Attribute, LSBareWord, LSString,
    Hash, HashEntryNode, PluginSectionNode
)

# åˆ›å»ºæ–°æ’ä»¶
new_plugin = Plugin(
    "mutate",
    tuple([
        Attribute(
            LSBareWord("add_field"),
            Hash(tuple([
                HashEntryNode(
                    LSString('"new_field"'),
                    LSString('"value"')
                )
            ]))
        )
    ])
)

# æ·»åŠ åˆ° filter æ®µï¼ˆchildren æ˜¯ tupleï¼Œéœ€è¦é‡æ–°åˆ›å»ºï¼‰
new_sections = []
for section in ast.children:
    if section.plugin_type == "filter":
        # åˆ›å»ºæ–°çš„ children tupleï¼ŒåŒ…å«åŸæœ‰æ’ä»¶å’Œæ–°æ’ä»¶
        new_children = section.children + (new_plugin,)
        new_section = PluginSectionNode(section.plugin_type, new_children)
        new_sections.append(new_section)
    else:
        new_sections.append(section)

# åˆ›å»ºæ–°çš„ Config
from logstash_parser.ast_nodes import Config
updated_ast = Config(tuple(new_sections))

# ç”Ÿæˆæ›´æ–°åçš„é…ç½®
updated_config = updated_ast.to_logstash()
print(updated_config)
```

**æ³¨æ„**: ç”±äº `children` æ˜¯ä¸å¯å˜çš„ `tuple`ï¼Œä¸èƒ½ç›´æ¥ä¿®æ”¹ã€‚éœ€è¦åˆ›å»ºæ–°çš„ tuple å¹¶é‡æ–°æ„å»ºèŠ‚ç‚¹ã€‚

### 4. æ¡ä»¶è¡¨è¾¾å¼å¤„ç†

```python
from logstash_parser.ast_nodes import (
    Branch, IfCondition, ElseCondition,
    CompareExpression, SelectorNode, LSString
)

# åˆ›å»ºæ¡ä»¶åˆ†æ”¯
condition = CompareExpression(
    SelectorNode("[type]"),
    "==",
    LSString('"nginx"')
)

# ç›´æ¥ä½¿ç”¨è¡¨è¾¾å¼ï¼Œæ— éœ€åŒ…è£…
if_branch = IfCondition(
    condition,
    tuple([grok_plugin])  # children å¿…é¡»æ˜¯ tuple
)

else_branch = ElseCondition(tuple([mutate_plugin]))  # children å¿…é¡»æ˜¯ tuple

branch = Branch(if_branch, [], else_branch)

# æ·»åŠ åˆ° filter æ®µï¼ˆéœ€è¦é‡æ–°åˆ›å»º sectionï¼‰
new_sections = []
for section in ast.children:
    if section.plugin_type == "filter":
        new_children = section.children + (branch,)
        new_section = PluginSectionNode(section.plugin_type, new_children)
        new_sections.append(new_section)
    else:
        new_sections.append(section)

# åˆ›å»ºæ–°çš„ Config
updated_ast = Config(tuple(new_sections))
```

### 5. éªŒè¯é…ç½®

```python
from pydantic import ValidationError

try:
    schema = ConfigSchema.model_validate(data)
    print("âœ… é…ç½®æœ‰æ•ˆ")
except ValidationError as e:
    print(f"âŒ é…ç½®æ— æ•ˆ:")
    for error in e.errors():
        print(f"  - {error['loc']}: {error['msg']}")
```

### 6. éƒ¨åˆ†åºåˆ—åŒ–

```python
# Schema ä¸åŒ…å« source_textï¼Œå·²ç»æ˜¯æœ€å°åŒ–çš„
data = schema.model_dump()

# æ’é™¤ None å€¼
minimal_data = schema.model_dump(exclude_none=True)

# åªåºåˆ—åŒ–ç‰¹å®šå­—æ®µï¼ˆæ ¹æ®å®é™… Schema ç»“æ„ï¼‰
# ä¾‹å¦‚ï¼Œå¯¹äº ConfigSchema:
partial_data = schema.model_dump(include={'config'})
```

### 7. ç”Ÿæˆ JSON Schema

```python
# ç”Ÿæˆ JSON Schemaï¼ˆç”¨äºæ–‡æ¡£æˆ–éªŒè¯ï¼‰
json_schema = ConfigSchema.model_json_schema()

import json
print(json.dumps(json_schema, indent=2))
```

---

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
from logstash_parser import parse_logstash_config, ParseError

try:
    ast = parse_logstash_config(config_text)
except ParseError as e:
    print(f"è§£æå¤±è´¥: {e}")
    # å¤„ç†é”™è¯¯
```

### 2. ç±»å‹æ£€æŸ¥

```python
from logstash_parser.ast_nodes import Plugin, Branch

for child in section.children:
    if isinstance(child, Plugin):
        print(f"æ’ä»¶: {child.plugin_name}")
    elif isinstance(child, Branch):
        print("åˆ†æ”¯")
```

### 3. ä½¿ç”¨ Schema éªŒè¯

```python
# åœ¨æ¥æ”¶å¤–éƒ¨æ•°æ®æ—¶ä½¿ç”¨ Schema éªŒè¯
def load_config(json_str: str):
    try:
        schema = ConfigSchema.model_validate_json(json_str)
        return Config.from_python(schema)
    except ValidationError as e:
        raise ValueError(f"æ— æ•ˆçš„é…ç½®: {e}")
```

### 4. ä¿ç•™æºæ–‡æœ¬

```python
# è§£ææ—¶ä¿ç•™æºæ–‡æœ¬
ast = parse_logstash_config(config_text)

# è·å–æºæ–‡æœ¬
source = ast.get_source_text()
if source:
    print(f"åŸå§‹æ–‡æœ¬: {source}")
```

### 5. å¢é‡æ„å»ºé…ç½®

```python
from logstash_parser.ast_nodes import Config, PluginSectionNode

# åˆ›å»ºå„ä¸ªæ®µ
input_section = PluginSectionNode("input", tuple([beats_plugin]))
filter_section = PluginSectionNode("filter", tuple([grok_plugin]))
output_section = PluginSectionNode("output", tuple([es_plugin]))

# åˆ›å»ºé…ç½®ï¼ˆä¸€æ¬¡æ€§æ„å»ºï¼‰
config = Config(tuple([input_section, filter_section, output_section]))
```

**æ³¨æ„**: ç”±äº `children` æ˜¯ `tuple`ï¼Œå»ºè®®ä¸€æ¬¡æ€§æ„å»ºå®Œæ•´çš„é…ç½®ç»“æ„ï¼Œè€Œä¸æ˜¯é€æ­¥æ·»åŠ ã€‚

### 6. é…ç½®åˆå¹¶

```python
def merge_configs(config1, config2):
    """åˆå¹¶ä¸¤ä¸ªé…ç½®"""
    merged_sections = []

    # åˆå¹¶å„ä¸ªæ®µ
    for section_type in ["input", "filter", "output"]:
        sections1 = [s for s in config1.children if s.plugin_type == section_type]
        sections2 = [s for s in config2.children if s.plugin_type == section_type]

        if sections1 or sections2:
            # æ”¶é›†æ‰€æœ‰ children
            all_children = []
            for s in sections1 + sections2:
                all_children.extend(s.children)

            # åˆ›å»ºåˆå¹¶åçš„ section
            merged_section = PluginSectionNode(section_type, tuple(all_children))
            merged_sections.append(merged_section)

    return Config(tuple(merged_sections))
```

**æ³¨æ„**: ç”±äº `children` æ˜¯ `tuple`ï¼Œéœ€è¦å…ˆæ”¶é›†æ‰€æœ‰å­èŠ‚ç‚¹åˆ° listï¼Œç„¶åè½¬æ¢ä¸º tuple åˆ›å»ºæ–°èŠ‚ç‚¹ã€‚

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†å¤æ‚çš„æ¡ä»¶è¡¨è¾¾å¼ï¼Ÿ

**A:** ä½¿ç”¨ `BooleanExpression` ç»„åˆå¤šä¸ªæ¡ä»¶ï¼š

```python
from logstash_parser.ast_nodes import BooleanExpression

# [type] == "nginx" and [status] == 200
condition = BooleanExpression(
    CompareExpression(SelectorNode("[type]"), "==", LSString('"nginx"')),
    "and",
    CompareExpression(SelectorNode("[status]"), "==", Number(200))
)
```

**è¿ç®—ç¬¦ä¼˜å…ˆçº§ï¼š**

å¸ƒå°”è¿ç®—ç¬¦éµå¾ªä»¥ä¸‹ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š

- `and` / `nand`ï¼ˆä¼˜å…ˆçº§ 3ï¼‰
- `xor`ï¼ˆä¼˜å…ˆçº§ 2ï¼‰
- `or`ï¼ˆä¼˜å…ˆçº§ 1ï¼‰

è§£æå™¨ä¼šè‡ªåŠ¨æ ¹æ®ä¼˜å…ˆçº§æ·»åŠ æ‹¬å·ï¼š

```python
# A or B and C ä¼šè¢«è§£æä¸º A or (B and C)
config = """
filter {
    if [a] or [b] and [c] {
        mutate {}
    }
}
"""
ast = parse_logstash_config(config)
# ç”Ÿæˆæ—¶ä¼šä¿ç•™æ­£ç¡®çš„ä¼˜å…ˆçº§
```

### Q2: å¦‚ä½•å¤„ç†åµŒå¥—çš„å“ˆå¸Œè¡¨ï¼Ÿ

**A:** é€’å½’åˆ›å»º `Hash` å’Œ `HashEntryNode`ï¼š

```python
nested_hash = Hash(tuple([
    HashEntryNode(
        LSString('"outer"'),
        Hash(tuple([
            HashEntryNode(
                LSString('"inner"'),
                LSString('"value"')
            )
        ]))
    )
]))
```

### Q3: å¦‚ä½•éªŒè¯ç”Ÿæˆçš„é…ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ

**A:** é‡æ–°è§£æç”Ÿæˆçš„é…ç½®ï¼š

```python
# ç”Ÿæˆé…ç½®
output_text = ast.to_logstash()

# é‡æ–°è§£æ
reparsed_ast = parse_logstash_config(output_text)

# æ¯”è¾ƒç»“æ„
assert ast.to_python() == reparsed_ast.to_python()
```

### Q4: å¦‚ä½•å¤„ç†å¤§å‹é…ç½®æ–‡ä»¶ï¼Ÿ

**A:** ä½¿ç”¨æµå¼å¤„ç†æˆ–åˆ†æ®µå¤„ç†ï¼š

```python
# åˆ†æ®µè§£æ
sections = config_text.split('\n\n')
for section in sections:
    if section.strip():
        try:
            ast = parse_logstash_config(section)
            # å¤„ç†æ¯ä¸ªæ®µ
        except ParseError:
            continue
```

### Q5: å¦‚ä½•è‡ªå®šä¹‰åºåˆ—åŒ–æ ¼å¼ï¼Ÿ

**A:** ä½¿ç”¨ Pydantic çš„åºåˆ—åŒ–é€‰é¡¹ï¼š

```python
# è‡ªå®šä¹‰åºåˆ—åŒ–
json_str = schema.model_dump_json(
    indent=2,
    exclude_none=True,
    by_alias=True
)
```

### Q6: å¦‚ä½•ä½¿ç”¨æ–¹æ³•è°ƒç”¨ï¼ˆMethodCallï¼‰ï¼Ÿ

**A:** æ–¹æ³•è°ƒç”¨å¯ç”¨äºæ¡ä»¶è¡¨è¾¾å¼çš„å³å€¼ä½ç½®ï¼š

```python
from logstash_parser.ast_nodes import (
    MethodCall, CompareExpression, SelectorNode, LSString
)

# åˆ›å»ºæ–¹æ³•è°ƒç”¨
method = MethodCall("sprintf", (LSString('"%{pattern}"'),))

# åœ¨æ¡ä»¶è¡¨è¾¾å¼ä¸­ä½¿ç”¨
condition = CompareExpression(
    SelectorNode("[field]"),
    "==",
    method
)

# åµŒå¥—æ–¹æ³•è°ƒç”¨
inner = MethodCall("lower", (SelectorNode("[name]"),))
outer = MethodCall("upper", (inner,))
```

**è§£æç¤ºä¾‹**:

```python
config = """
filter {
    if [field] == sprintf("%{pattern}") {
        mutate { add_tag => ["matched"] }
    }
}
"""
ast = parse_logstash_config(config)
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: è§£æå¤±è´¥

**ç—‡çŠ¶ï¼š** `ParseError: Failed to parse configuration`

**è§£å†³æ–¹æ¡ˆï¼š**

1. æ£€æŸ¥é…ç½®è¯­æ³•æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿å¼•å·åŒ¹é…
3. æ£€æŸ¥æ‹¬å·æ˜¯å¦é—­åˆ
4. éªŒè¯æ“ä½œç¬¦æ˜¯å¦æ­£ç¡®

```python
# è°ƒè¯•è§£æ
try:
    ast = parse_logstash_config(config_text)
except ParseError as e:
    print(f"è§£æé”™è¯¯: {e}")
    # é€è¡Œæ£€æŸ¥
    for i, line in enumerate(config_text.split('\n'), 1):
        print(f"{i}: {line}")
```

### é—®é¢˜ 2: åºåˆ—åŒ–å¤±è´¥

**ç—‡çŠ¶ï¼š** `ValidationError` æˆ–åºåˆ—åŒ–é”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**

1. æ£€æŸ¥æ•°æ®ç±»å‹æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿å¿…å¡«å­—æ®µå­˜åœ¨
3. éªŒè¯å­—æ®µå€¼æ˜¯å¦æœ‰æ•ˆ

```python
# è°ƒè¯•åºåˆ—åŒ–
try:
    json_str = schema.model_dump_json()
except Exception as e:
    print(f"åºåˆ—åŒ–é”™è¯¯: {e}")
    # æ£€æŸ¥ schema
    print(schema.model_dump())
```

### é—®é¢˜ 3: ç±»å‹é”™è¯¯

**ç—‡çŠ¶ï¼š** `TypeError` æˆ–ç±»å‹ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**

1. ä½¿ç”¨ç±»å‹æ£€æŸ¥
2. éªŒè¯èŠ‚ç‚¹ç±»å‹
3. ä½¿ç”¨ isinstance æ£€æŸ¥

```python
# ç±»å‹æ£€æŸ¥
from logstash_parser.ast_nodes import Plugin

if isinstance(node, Plugin):
    print(f"æ’ä»¶å: {node.plugin_name}")
else:
    print(f"ä¸æ˜¯æ’ä»¶èŠ‚ç‚¹: {type(node)}")
```

### é—®é¢˜ 4: å†…å­˜å ç”¨è¿‡é«˜

**ç—‡çŠ¶ï¼š** å¤„ç†å¤§å‹é…ç½®æ—¶å†…å­˜å ç”¨é«˜

**è§£å†³æ–¹æ¡ˆï¼š**

1. ä½¿ç”¨æµå¼å¤„ç†
2. åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¯¹è±¡
3. Schema ä¸åŒ…å« source_textï¼Œå·²ç»æ˜¯æœ€å°åŒ–çš„

```python
# Schema å·²ç»ä¸åŒ…å« source_text
schema = ast.to_python(as_pydantic=True)
json_str = schema.model_dump_json()
```

### é—®é¢˜ 5: æ€§èƒ½é—®é¢˜

**ç—‡çŠ¶ï¼š** è§£ææˆ–åºåˆ—åŒ–é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆï¼š**

1. ä½¿ç”¨ç¼“å­˜
2. æ‰¹é‡å¤„ç†
3. é¿å…é‡å¤è§£æ

```python
# ä½¿ç”¨ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=128)
def parse_cached(config_text):
    return parse_logstash_config(config_text)
```

---

## ç¤ºä¾‹é›†åˆ

### ç¤ºä¾‹ 1: å®Œæ•´çš„è½¬æ¢é“¾

```python
from logstash_parser import parse_logstash_config
from logstash_parser.schemas import ConfigSchema
from logstash_parser.ast_nodes import Config

# 1. è§£æ
ast = parse_logstash_config(config_text)

# 2. AST â†’ Schema
schema = ast.to_python(as_pydantic=True)

# 3. Schema â†’ JSON
json_str = schema.model_dump_json(indent=2)

# 4. JSON â†’ Schema
loaded_schema = ConfigSchema.model_validate_json(json_str)

# 5. Schema â†’ AST
reconstructed_ast = Config.from_python(loaded_schema)

# 6. AST â†’ Logstash
output_text = reconstructed_ast.to_logstash()

# éªŒè¯
assert ast.to_python() == reconstructed_ast.to_python()
```

### ç¤ºä¾‹ 2: é…ç½®æ¨¡æ¿

```python
def create_grok_filter(pattern):
    """åˆ›å»º grok filter æ¨¡æ¿"""
    return Plugin(
        "grok",
        tuple([
            Attribute(
                LSBareWord("match"),
                Hash(tuple([
                    HashEntryNode(
                        LSString('"message"'),
                        LSString(f'"{pattern}"')
                    )
                ]))
            )
        ])
    )

# ä½¿ç”¨æ¨¡æ¿
nginx_filter = create_grok_filter("%{COMBINEDAPACHELOG}")
syslog_filter = create_grok_filter("%{SYSLOGLINE}")
```

### ç¤ºä¾‹ 3: é…ç½®éªŒè¯å™¨

```python
def validate_config(config_text):
    """éªŒè¯ Logstash é…ç½®"""
    try:
        # è§£æ
        ast = parse_logstash_config(config_text)

        # è½¬æ¢ä¸º Schemaï¼ˆè§¦å‘éªŒè¯ï¼‰
        schema = ast.to_python(as_pydantic=True)

        # æ£€æŸ¥å¿…è¦çš„æ®µï¼ˆä» ConfigSchema è·å–ï¼‰
        plugin_types = set()
        for section_schema in schema.config:
            # PluginSectionSchema çš„ plugin_section æ˜¯ dict
            plugin_types.update(section_schema.plugin_section.keys())

        if 'input' not in plugin_types:
            return False, "ç¼ºå°‘ input æ®µ"
        if 'output' not in plugin_types:
            return False, "ç¼ºå°‘ output æ®µ"

        return True, "é…ç½®æœ‰æ•ˆ"
    except Exception as e:
        return False, str(e)

# ä½¿ç”¨
is_valid, message = validate_config(config_text)
print(f"{'âœ…' if is_valid else 'âŒ'} {message}")
```

### ç¤ºä¾‹ 4: ä½¿ç”¨æ–¹æ³•è°ƒç”¨

```python
from logstash_parser.ast_nodes import (
    MethodCall, IfCondition, CompareExpression,
    SelectorNode, LSString, Plugin, Attribute,
    LSBareWord, Hash, HashEntryNode
)

# åˆ›å»ºå¸¦æ–¹æ³•è°ƒç”¨çš„æ¡ä»¶
method = MethodCall("sprintf", (LSString('"%{expected_status}"'),))
condition = CompareExpression(
    SelectorNode("[status]"),
    "==",
    method
)

# åˆ›å»ºæ’ä»¶
mutate = Plugin("mutate", tuple([
    Attribute(
        LSBareWord("add_tag"),
        Array((LSString('"matched"'),))
    )
]))

# åˆ›å»ºæ¡ä»¶åˆ†æ”¯
if_branch = IfCondition(condition, tuple([mutate]))

# ä½¿ç”¨ç¤ºä¾‹
config = """
filter {
    if [status] == sprintf("%{expected_status}") {
        mutate {
            add_tag => ["matched"]
        }
    }
}
"""
ast = parse_logstash_config(config)
print(ast.to_logstash())
```

---

## ç›¸å…³æ–‡æ¡£

- [æ¶æ„è®¾è®¡](./ARCHITECTURE.md)
- [API å‚è€ƒ](./API_REFERENCE.md)
- [æµ‹è¯•æŒ‡å—](./TESTING.md)
- [æ›´æ–°æ—¥å¿—](./CHANGELOG.md)
